{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "- Data preprocessing is a process of preparing the raw data and making it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model.\n",
    "\n",
    "\n",
    "\n",
    "- When creating a machine learning project, it is not always a case that we come across the clean and formatted data. \n",
    "\n",
    "\n",
    "\n",
    "- And while doing any operation with data, it is mandatory to clean it and put in a formatted way. So for this, we use data preprocessing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series(['10','20','30'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110\n",
       "1    120\n",
       "2    130\n",
       "dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.astype(int)+100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the need of Data Preprocessing?\n",
    "\n",
    "o A real-world data generally contains noises, missing values, and maybe in an unusable format which cannot be directly used for machine learning models. \n",
    "\n",
    "\n",
    "o Data preprocessing is required tasks for cleaning the data and making it suitable for a machine learning model which also increases the accuracy and efficiency of a machine learning model.\n",
    "\n",
    "#### It involves below steps:\n",
    "\n",
    "    Finding Missing Data\n",
    "    Encoding Categorical Data\n",
    "    Splitting dataset into training and test set\n",
    "    Feature scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country , age and salary\n",
    "data = [['India',np.nan,68000.0],  \n",
    "    ['France',43.0,45000.0],  \n",
    " [np.nan,30.0, 54000.0],  \n",
    " ['France' ,48.0, 65000.0], \n",
    " ['Germany' ,40.0, np. nan],  \n",
    " ['India' ,35.0, 58000.0],  \n",
    " ['Germany', np.nan ,53000.0],  \n",
    " ['France' ,49.0, 79000.0],  \n",
    " ['India', 50.0 ,88000.0],  \n",
    " [np.nan ,37.0, np.nan]]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>India</td>\n",
       "      <td>50.0</td>\n",
       "      <td>88000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1        2\n",
       "0    India   NaN  68000.0\n",
       "1   France  43.0  45000.0\n",
       "2      NaN  30.0  54000.0\n",
       "3   France  48.0  65000.0\n",
       "4  Germany  40.0      NaN\n",
       "5    India  35.0  58000.0\n",
       "6  Germany   NaN  53000.0\n",
       "7   France  49.0  79000.0\n",
       "8    India  50.0  88000.0\n",
       "9      NaN  37.0      NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment: Convert above DataFrame into csv file and check what happens to NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiggnment: check library missingno\n",
    "# Plot the NaN present in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways to handle missing data:\n",
    "\n",
    "#### There are mainly two ways to handle missing data, which are:\n",
    "\n",
    "- *By deleting the particular row:* The first way is used to commonly deal with null values. In this way, we just delete the specific row or column which consists of null values. But this way is not so efficient and removing data may lead to loss of information which will not give the accurate output.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- *By calculating the mean:* In this way, we will calculate the mean of that column or row which contains any missing value and will put it on the place of missing value. This strategy is useful for the features which have numeric data such as age, salary, etc. Here, we will use this approach. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Using pandas which options are availabel to fill the missing entries:\n",
    "ffill/pad, backfill/bfill\n",
    "fillna()\n",
    "dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>missing</td>\n",
       "      <td>68000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>missing</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>missing</td>\n",
       "      <td>53000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>India</td>\n",
       "      <td>50.0</td>\n",
       "      <td>88000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>missing</td>\n",
       "      <td>37.0</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2\n",
       "0    India  missing  68000.0\n",
       "1   France     43.0  45000.0\n",
       "2  missing     30.0  54000.0\n",
       "3   France     48.0  65000.0\n",
       "4  Germany     40.0  missing\n",
       "5    India     35.0  58000.0\n",
       "6  Germany  missing  53000.0\n",
       "7   France     49.0  79000.0\n",
       "8    India     50.0  88000.0\n",
       "9  missing     37.0  missing"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      India\n",
       "1     France\n",
       "2    unknown\n",
       "3     France\n",
       "4    Germany\n",
       "5      India\n",
       "6    Germany\n",
       "7     France\n",
       "8      India\n",
       "9    unknown\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only use first column to fill missing entries\n",
    "df.iloc[:,0].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second column we have is age hence we need to replace\n",
    "# NaN values using average(mean) age\n",
    "df.iloc[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    42.0\n",
       "1    43.0\n",
       "2    30.0\n",
       "3    48.0\n",
       "4    40.0\n",
       "5    35.0\n",
       "6    42.0\n",
       "7    49.0\n",
       "8    50.0\n",
       "9    37.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is age column hence we have to fill using mean()\n",
    "# df.iloc[:,1].mean()\n",
    "df.iloc[:,1].fillna(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1    43.0\n",
       "2    30.0\n",
       "3    48.0\n",
       "4    40.0\n",
       "5    35.0\n",
       "6    35.0\n",
       "7    49.0\n",
       "8    50.0\n",
       "9    37.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ffill/pad---> forward filling\n",
    "#df.iloc[:,1].fillna(method='ffill')\n",
    "df.iloc[:,1].fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68000.0\n",
       "1    45000.0\n",
       "2    54000.0\n",
       "3    65000.0\n",
       "4    65000.0\n",
       "5    58000.0\n",
       "6    53000.0\n",
       "7    79000.0\n",
       "8    88000.0\n",
       "9    88000.0\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    43.0\n",
       "1    43.0\n",
       "2    30.0\n",
       "3    48.0\n",
       "4    40.0\n",
       "5    35.0\n",
       "6    49.0\n",
       "7    49.0\n",
       "8    50.0\n",
       "9    37.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bfill/backfill --> backward filling means fill Nan by taking bottom value\n",
    "df.iloc[:,1].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68000.0\n",
       "1    45000.0\n",
       "2    54000.0\n",
       "3    65000.0\n",
       "4    58000.0\n",
       "5    58000.0\n",
       "6    53000.0\n",
       "7    79000.0\n",
       "8    88000.0\n",
       "9        NaN\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,2].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "India      3\n",
       "France     3\n",
       "Germany    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    France\n",
       "1     India\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      India\n",
       "1     France\n",
       "2      India\n",
       "3     France\n",
       "4    Germany\n",
       "5      India\n",
       "6    Germany\n",
       "7     France\n",
       "8      India\n",
       "9      India\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0].fillna('India')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "#handling missing data (Replacing missing data with the mean value\n",
    "#in respective column) \n",
    "\n",
    "#create an object of SimpleImputer\n",
    "si = SimpleImputer()\n",
    "#Other missing examples: -999 -99 -1 -111 NA==> missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The imputation strategy.\n",
    "\n",
    "    - If \"mean\", then replace missing values using the mean along\n",
    "      each column. Can only be used with numeric data.\n",
    "    - If \"median\", then replace missing values using the median along\n",
    "      each column. Can only be used with numeric data.\n",
    "    - If \"most_frequent\", then replace missing using the most frequent\n",
    "      value along each column. Can be used with strings or numeric data.\n",
    "      If there is more than one such value, only the smallest is returned.\n",
    "    - If \"constant\", then replace missing values with fill_value. Can be\n",
    "      used with strings or numeric data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.0</td>\n",
       "      <td>88000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2\n",
       "0   NaN  68000.0\n",
       "1  43.0  45000.0\n",
       "2  30.0  54000.0\n",
       "3  48.0  65000.0\n",
       "4  40.0      NaN\n",
       "5  35.0  58000.0\n",
       "6   NaN  53000.0\n",
       "7  49.0  79000.0\n",
       "8  50.0  88000.0\n",
       "9  37.0      NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting imputer object to the independent variables x with numeric dtype \n",
    "ndf = df.select_dtypes(exclude='object')\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.fit(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit means training \n",
    "#it gives information about data u supplied\n",
    "si.missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>68000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.0</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>65000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49.0</td>\n",
       "      <td>79000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.0</td>\n",
       "      <td>88000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2\n",
       "0   NaN  68000.0\n",
       "1  43.0  45000.0\n",
       "2  30.0  54000.0\n",
       "3  48.0  65000.0\n",
       "4  40.0      NaN\n",
       "5  35.0  58000.0\n",
       "6   NaN  53000.0\n",
       "7  49.0  79000.0\n",
       "8  50.0  88000.0\n",
       "9  37.0      NaN"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.150e+01, 6.800e+04],\n",
       "       [4.300e+01, 4.500e+04],\n",
       "       [3.000e+01, 5.400e+04],\n",
       "       [4.800e+01, 6.500e+04],\n",
       "       [4.000e+01, 6.375e+04],\n",
       "       [3.500e+01, 5.800e+04],\n",
       "       [4.150e+01, 5.300e+04],\n",
       "       [4.900e+01, 7.900e+04],\n",
       "       [5.000e+01, 8.800e+04],\n",
       "       [3.700e+01, 6.375e+04]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing missing data with the calculated mean value using transform\n",
    "si.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       41.5\n",
       "2    63750.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.150e+01, 6.800e+04],\n",
       "       [4.300e+01, 4.500e+04],\n",
       "       [3.000e+01, 5.400e+04],\n",
       "       [4.800e+01, 6.500e+04],\n",
       "       [4.000e+01, 6.375e+04],\n",
       "       [3.500e+01, 5.800e+04],\n",
       "       [4.150e+01, 5.300e+04],\n",
       "       [4.900e+01, 7.900e+04],\n",
       "       [5.000e+01, 8.800e+04],\n",
       "       [3.700e+01, 6.375e+04]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to perform fit and transform together?\n",
    "si.fit_transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "t = sns.load_dataset('titanic')\n",
    "t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    29.699118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[['age']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ],\n",
       "       [38.        ],\n",
       "       [26.        ],\n",
       "       [35.        ],\n",
       "       [35.        ],\n",
       "       [29.69911765],\n",
       "       [54.        ],\n",
       "       [ 2.        ],\n",
       "       [27.        ],\n",
       "       [14.        ],\n",
       "       [ 4.        ],\n",
       "       [58.        ],\n",
       "       [20.        ],\n",
       "       [39.        ],\n",
       "       [14.        ],\n",
       "       [55.        ],\n",
       "       [ 2.        ],\n",
       "       [29.69911765],\n",
       "       [31.        ],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [34.        ],\n",
       "       [15.        ],\n",
       "       [28.        ],\n",
       "       [ 8.        ],\n",
       "       [38.        ],\n",
       "       [29.69911765],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [40.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [66.        ],\n",
       "       [28.        ],\n",
       "       [42.        ],\n",
       "       [29.69911765],\n",
       "       [21.        ],\n",
       "       [18.        ],\n",
       "       [14.        ],\n",
       "       [40.        ],\n",
       "       [27.        ],\n",
       "       [29.69911765],\n",
       "       [ 3.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [ 7.        ],\n",
       "       [21.        ],\n",
       "       [49.        ],\n",
       "       [29.        ],\n",
       "       [65.        ],\n",
       "       [29.69911765],\n",
       "       [21.        ],\n",
       "       [28.5       ],\n",
       "       [ 5.        ],\n",
       "       [11.        ],\n",
       "       [22.        ],\n",
       "       [38.        ],\n",
       "       [45.        ],\n",
       "       [ 4.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.        ],\n",
       "       [19.        ],\n",
       "       [17.        ],\n",
       "       [26.        ],\n",
       "       [32.        ],\n",
       "       [16.        ],\n",
       "       [21.        ],\n",
       "       [26.        ],\n",
       "       [32.        ],\n",
       "       [25.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [ 0.83      ],\n",
       "       [30.        ],\n",
       "       [22.        ],\n",
       "       [29.        ],\n",
       "       [29.69911765],\n",
       "       [28.        ],\n",
       "       [17.        ],\n",
       "       [33.        ],\n",
       "       [16.        ],\n",
       "       [29.69911765],\n",
       "       [23.        ],\n",
       "       [24.        ],\n",
       "       [29.        ],\n",
       "       [20.        ],\n",
       "       [46.        ],\n",
       "       [26.        ],\n",
       "       [59.        ],\n",
       "       [29.69911765],\n",
       "       [71.        ],\n",
       "       [23.        ],\n",
       "       [34.        ],\n",
       "       [34.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [21.        ],\n",
       "       [33.        ],\n",
       "       [37.        ],\n",
       "       [28.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [38.        ],\n",
       "       [29.69911765],\n",
       "       [47.        ],\n",
       "       [14.5       ],\n",
       "       [22.        ],\n",
       "       [20.        ],\n",
       "       [17.        ],\n",
       "       [21.        ],\n",
       "       [70.5       ],\n",
       "       [29.        ],\n",
       "       [24.        ],\n",
       "       [ 2.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [32.5       ],\n",
       "       [32.5       ],\n",
       "       [54.        ],\n",
       "       [12.        ],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [45.        ],\n",
       "       [33.        ],\n",
       "       [20.        ],\n",
       "       [47.        ],\n",
       "       [29.        ],\n",
       "       [25.        ],\n",
       "       [23.        ],\n",
       "       [19.        ],\n",
       "       [37.        ],\n",
       "       [16.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [22.        ],\n",
       "       [24.        ],\n",
       "       [19.        ],\n",
       "       [18.        ],\n",
       "       [19.        ],\n",
       "       [27.        ],\n",
       "       [ 9.        ],\n",
       "       [36.5       ],\n",
       "       [42.        ],\n",
       "       [51.        ],\n",
       "       [22.        ],\n",
       "       [55.5       ],\n",
       "       [40.5       ],\n",
       "       [29.69911765],\n",
       "       [51.        ],\n",
       "       [16.        ],\n",
       "       [30.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [44.        ],\n",
       "       [40.        ],\n",
       "       [26.        ],\n",
       "       [17.        ],\n",
       "       [ 1.        ],\n",
       "       [ 9.        ],\n",
       "       [29.69911765],\n",
       "       [45.        ],\n",
       "       [29.69911765],\n",
       "       [28.        ],\n",
       "       [61.        ],\n",
       "       [ 4.        ],\n",
       "       [ 1.        ],\n",
       "       [21.        ],\n",
       "       [56.        ],\n",
       "       [18.        ],\n",
       "       [29.69911765],\n",
       "       [50.        ],\n",
       "       [30.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [ 9.        ],\n",
       "       [ 1.        ],\n",
       "       [ 4.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [45.        ],\n",
       "       [40.        ],\n",
       "       [36.        ],\n",
       "       [32.        ],\n",
       "       [19.        ],\n",
       "       [19.        ],\n",
       "       [ 3.        ],\n",
       "       [44.        ],\n",
       "       [58.        ],\n",
       "       [29.69911765],\n",
       "       [42.        ],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [34.        ],\n",
       "       [45.5       ],\n",
       "       [18.        ],\n",
       "       [ 2.        ],\n",
       "       [32.        ],\n",
       "       [26.        ],\n",
       "       [16.        ],\n",
       "       [40.        ],\n",
       "       [24.        ],\n",
       "       [35.        ],\n",
       "       [22.        ],\n",
       "       [30.        ],\n",
       "       [29.69911765],\n",
       "       [31.        ],\n",
       "       [27.        ],\n",
       "       [42.        ],\n",
       "       [32.        ],\n",
       "       [30.        ],\n",
       "       [16.        ],\n",
       "       [27.        ],\n",
       "       [51.        ],\n",
       "       [29.69911765],\n",
       "       [38.        ],\n",
       "       [22.        ],\n",
       "       [19.        ],\n",
       "       [20.5       ],\n",
       "       [18.        ],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [29.        ],\n",
       "       [59.        ],\n",
       "       [ 5.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [44.        ],\n",
       "       [ 8.        ],\n",
       "       [19.        ],\n",
       "       [33.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.        ],\n",
       "       [22.        ],\n",
       "       [30.        ],\n",
       "       [44.        ],\n",
       "       [25.        ],\n",
       "       [24.        ],\n",
       "       [37.        ],\n",
       "       [54.        ],\n",
       "       [29.69911765],\n",
       "       [29.        ],\n",
       "       [62.        ],\n",
       "       [30.        ],\n",
       "       [41.        ],\n",
       "       [29.        ],\n",
       "       [29.69911765],\n",
       "       [30.        ],\n",
       "       [35.        ],\n",
       "       [50.        ],\n",
       "       [29.69911765],\n",
       "       [ 3.        ],\n",
       "       [52.        ],\n",
       "       [40.        ],\n",
       "       [29.69911765],\n",
       "       [36.        ],\n",
       "       [16.        ],\n",
       "       [25.        ],\n",
       "       [58.        ],\n",
       "       [35.        ],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [41.        ],\n",
       "       [37.        ],\n",
       "       [29.69911765],\n",
       "       [63.        ],\n",
       "       [45.        ],\n",
       "       [29.69911765],\n",
       "       [ 7.        ],\n",
       "       [35.        ],\n",
       "       [65.        ],\n",
       "       [28.        ],\n",
       "       [16.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [33.        ],\n",
       "       [30.        ],\n",
       "       [22.        ],\n",
       "       [42.        ],\n",
       "       [22.        ],\n",
       "       [26.        ],\n",
       "       [19.        ],\n",
       "       [36.        ],\n",
       "       [24.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [23.5       ],\n",
       "       [ 2.        ],\n",
       "       [29.69911765],\n",
       "       [50.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [ 0.92      ],\n",
       "       [29.69911765],\n",
       "       [17.        ],\n",
       "       [30.        ],\n",
       "       [30.        ],\n",
       "       [24.        ],\n",
       "       [18.        ],\n",
       "       [26.        ],\n",
       "       [28.        ],\n",
       "       [43.        ],\n",
       "       [26.        ],\n",
       "       [24.        ],\n",
       "       [54.        ],\n",
       "       [31.        ],\n",
       "       [40.        ],\n",
       "       [22.        ],\n",
       "       [27.        ],\n",
       "       [30.        ],\n",
       "       [22.        ],\n",
       "       [29.69911765],\n",
       "       [36.        ],\n",
       "       [61.        ],\n",
       "       [36.        ],\n",
       "       [31.        ],\n",
       "       [16.        ],\n",
       "       [29.69911765],\n",
       "       [45.5       ],\n",
       "       [38.        ],\n",
       "       [16.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.        ],\n",
       "       [41.        ],\n",
       "       [45.        ],\n",
       "       [45.        ],\n",
       "       [ 2.        ],\n",
       "       [24.        ],\n",
       "       [28.        ],\n",
       "       [25.        ],\n",
       "       [36.        ],\n",
       "       [24.        ],\n",
       "       [40.        ],\n",
       "       [29.69911765],\n",
       "       [ 3.        ],\n",
       "       [42.        ],\n",
       "       [23.        ],\n",
       "       [29.69911765],\n",
       "       [15.        ],\n",
       "       [25.        ],\n",
       "       [29.69911765],\n",
       "       [28.        ],\n",
       "       [22.        ],\n",
       "       [38.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [40.        ],\n",
       "       [29.        ],\n",
       "       [45.        ],\n",
       "       [35.        ],\n",
       "       [29.69911765],\n",
       "       [30.        ],\n",
       "       [60.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [25.        ],\n",
       "       [18.        ],\n",
       "       [19.        ],\n",
       "       [22.        ],\n",
       "       [ 3.        ],\n",
       "       [29.69911765],\n",
       "       [22.        ],\n",
       "       [27.        ],\n",
       "       [20.        ],\n",
       "       [19.        ],\n",
       "       [42.        ],\n",
       "       [ 1.        ],\n",
       "       [32.        ],\n",
       "       [35.        ],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [ 1.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [17.        ],\n",
       "       [36.        ],\n",
       "       [21.        ],\n",
       "       [28.        ],\n",
       "       [23.        ],\n",
       "       [24.        ],\n",
       "       [22.        ],\n",
       "       [31.        ],\n",
       "       [46.        ],\n",
       "       [23.        ],\n",
       "       [28.        ],\n",
       "       [39.        ],\n",
       "       [26.        ],\n",
       "       [21.        ],\n",
       "       [28.        ],\n",
       "       [20.        ],\n",
       "       [34.        ],\n",
       "       [51.        ],\n",
       "       [ 3.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [33.        ],\n",
       "       [29.69911765],\n",
       "       [44.        ],\n",
       "       [29.69911765],\n",
       "       [34.        ],\n",
       "       [18.        ],\n",
       "       [30.        ],\n",
       "       [10.        ],\n",
       "       [29.69911765],\n",
       "       [21.        ],\n",
       "       [29.        ],\n",
       "       [28.        ],\n",
       "       [18.        ],\n",
       "       [29.69911765],\n",
       "       [28.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [42.        ],\n",
       "       [17.        ],\n",
       "       [50.        ],\n",
       "       [14.        ],\n",
       "       [21.        ],\n",
       "       [24.        ],\n",
       "       [64.        ],\n",
       "       [31.        ],\n",
       "       [45.        ],\n",
       "       [20.        ],\n",
       "       [25.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [ 4.        ],\n",
       "       [13.        ],\n",
       "       [34.        ],\n",
       "       [ 5.        ],\n",
       "       [52.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [30.        ],\n",
       "       [49.        ],\n",
       "       [29.69911765],\n",
       "       [29.        ],\n",
       "       [65.        ],\n",
       "       [29.69911765],\n",
       "       [50.        ],\n",
       "       [29.69911765],\n",
       "       [48.        ],\n",
       "       [34.        ],\n",
       "       [47.        ],\n",
       "       [48.        ],\n",
       "       [29.69911765],\n",
       "       [38.        ],\n",
       "       [29.69911765],\n",
       "       [56.        ],\n",
       "       [29.69911765],\n",
       "       [ 0.75      ],\n",
       "       [29.69911765],\n",
       "       [38.        ],\n",
       "       [33.        ],\n",
       "       [23.        ],\n",
       "       [22.        ],\n",
       "       [29.69911765],\n",
       "       [34.        ],\n",
       "       [29.        ],\n",
       "       [22.        ],\n",
       "       [ 2.        ],\n",
       "       [ 9.        ],\n",
       "       [29.69911765],\n",
       "       [50.        ],\n",
       "       [63.        ],\n",
       "       [25.        ],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [58.        ],\n",
       "       [30.        ],\n",
       "       [ 9.        ],\n",
       "       [29.69911765],\n",
       "       [21.        ],\n",
       "       [55.        ],\n",
       "       [71.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [54.        ],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [24.        ],\n",
       "       [17.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [37.        ],\n",
       "       [16.        ],\n",
       "       [18.        ],\n",
       "       [33.        ],\n",
       "       [29.69911765],\n",
       "       [28.        ],\n",
       "       [26.        ],\n",
       "       [29.        ],\n",
       "       [29.69911765],\n",
       "       [36.        ],\n",
       "       [54.        ],\n",
       "       [24.        ],\n",
       "       [47.        ],\n",
       "       [34.        ],\n",
       "       [29.69911765],\n",
       "       [36.        ],\n",
       "       [32.        ],\n",
       "       [30.        ],\n",
       "       [22.        ],\n",
       "       [29.69911765],\n",
       "       [44.        ],\n",
       "       [29.69911765],\n",
       "       [40.5       ],\n",
       "       [50.        ],\n",
       "       [29.69911765],\n",
       "       [39.        ],\n",
       "       [23.        ],\n",
       "       [ 2.        ],\n",
       "       [29.69911765],\n",
       "       [17.        ],\n",
       "       [29.69911765],\n",
       "       [30.        ],\n",
       "       [ 7.        ],\n",
       "       [45.        ],\n",
       "       [30.        ],\n",
       "       [29.69911765],\n",
       "       [22.        ],\n",
       "       [36.        ],\n",
       "       [ 9.        ],\n",
       "       [11.        ],\n",
       "       [32.        ],\n",
       "       [50.        ],\n",
       "       [64.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [33.        ],\n",
       "       [ 8.        ],\n",
       "       [17.        ],\n",
       "       [27.        ],\n",
       "       [29.69911765],\n",
       "       [22.        ],\n",
       "       [22.        ],\n",
       "       [62.        ],\n",
       "       [48.        ],\n",
       "       [29.69911765],\n",
       "       [39.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [40.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [19.        ],\n",
       "       [29.        ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [62.        ],\n",
       "       [53.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [16.        ],\n",
       "       [19.        ],\n",
       "       [34.        ],\n",
       "       [39.        ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [25.        ],\n",
       "       [39.        ],\n",
       "       [54.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [47.        ],\n",
       "       [60.        ],\n",
       "       [22.        ],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [52.        ],\n",
       "       [47.        ],\n",
       "       [29.69911765],\n",
       "       [37.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [49.        ],\n",
       "       [29.69911765],\n",
       "       [49.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [44.        ],\n",
       "       [35.        ],\n",
       "       [36.        ],\n",
       "       [30.        ],\n",
       "       [27.        ],\n",
       "       [22.        ],\n",
       "       [40.        ],\n",
       "       [39.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [24.        ],\n",
       "       [34.        ],\n",
       "       [26.        ],\n",
       "       [ 4.        ],\n",
       "       [26.        ],\n",
       "       [27.        ],\n",
       "       [42.        ],\n",
       "       [20.        ],\n",
       "       [21.        ],\n",
       "       [21.        ],\n",
       "       [61.        ],\n",
       "       [57.        ],\n",
       "       [21.        ],\n",
       "       [26.        ],\n",
       "       [29.69911765],\n",
       "       [80.        ],\n",
       "       [51.        ],\n",
       "       [32.        ],\n",
       "       [29.69911765],\n",
       "       [ 9.        ],\n",
       "       [28.        ],\n",
       "       [32.        ],\n",
       "       [31.        ],\n",
       "       [41.        ],\n",
       "       [29.69911765],\n",
       "       [20.        ],\n",
       "       [24.        ],\n",
       "       [ 2.        ],\n",
       "       [29.69911765],\n",
       "       [ 0.75      ],\n",
       "       [48.        ],\n",
       "       [19.        ],\n",
       "       [56.        ],\n",
       "       [29.69911765],\n",
       "       [23.        ],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [23.        ],\n",
       "       [58.        ],\n",
       "       [50.        ],\n",
       "       [40.        ],\n",
       "       [47.        ],\n",
       "       [36.        ],\n",
       "       [20.        ],\n",
       "       [32.        ],\n",
       "       [25.        ],\n",
       "       [29.69911765],\n",
       "       [43.        ],\n",
       "       [29.69911765],\n",
       "       [40.        ],\n",
       "       [31.        ],\n",
       "       [70.        ],\n",
       "       [31.        ],\n",
       "       [29.69911765],\n",
       "       [18.        ],\n",
       "       [24.5       ],\n",
       "       [18.        ],\n",
       "       [43.        ],\n",
       "       [36.        ],\n",
       "       [29.69911765],\n",
       "       [27.        ],\n",
       "       [20.        ],\n",
       "       [14.        ],\n",
       "       [60.        ],\n",
       "       [25.        ],\n",
       "       [14.        ],\n",
       "       [19.        ],\n",
       "       [18.        ],\n",
       "       [15.        ],\n",
       "       [31.        ],\n",
       "       [ 4.        ],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [60.        ],\n",
       "       [52.        ],\n",
       "       [44.        ],\n",
       "       [29.69911765],\n",
       "       [49.        ],\n",
       "       [42.        ],\n",
       "       [18.        ],\n",
       "       [35.        ],\n",
       "       [18.        ],\n",
       "       [25.        ],\n",
       "       [26.        ],\n",
       "       [39.        ],\n",
       "       [45.        ],\n",
       "       [42.        ],\n",
       "       [22.        ],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [48.        ],\n",
       "       [29.        ],\n",
       "       [52.        ],\n",
       "       [19.        ],\n",
       "       [38.        ],\n",
       "       [27.        ],\n",
       "       [29.69911765],\n",
       "       [33.        ],\n",
       "       [ 6.        ],\n",
       "       [17.        ],\n",
       "       [34.        ],\n",
       "       [50.        ],\n",
       "       [27.        ],\n",
       "       [20.        ],\n",
       "       [30.        ],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [25.        ],\n",
       "       [29.        ],\n",
       "       [11.        ],\n",
       "       [29.69911765],\n",
       "       [23.        ],\n",
       "       [23.        ],\n",
       "       [28.5       ],\n",
       "       [48.        ],\n",
       "       [35.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [36.        ],\n",
       "       [21.        ],\n",
       "       [24.        ],\n",
       "       [31.        ],\n",
       "       [70.        ],\n",
       "       [16.        ],\n",
       "       [30.        ],\n",
       "       [19.        ],\n",
       "       [31.        ],\n",
       "       [ 4.        ],\n",
       "       [ 6.        ],\n",
       "       [33.        ],\n",
       "       [23.        ],\n",
       "       [48.        ],\n",
       "       [ 0.67      ],\n",
       "       [28.        ],\n",
       "       [18.        ],\n",
       "       [34.        ],\n",
       "       [33.        ],\n",
       "       [29.69911765],\n",
       "       [41.        ],\n",
       "       [20.        ],\n",
       "       [36.        ],\n",
       "       [16.        ],\n",
       "       [51.        ],\n",
       "       [29.69911765],\n",
       "       [30.5       ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [24.        ],\n",
       "       [48.        ],\n",
       "       [57.        ],\n",
       "       [29.69911765],\n",
       "       [54.        ],\n",
       "       [18.        ],\n",
       "       [29.69911765],\n",
       "       [ 5.        ],\n",
       "       [29.69911765],\n",
       "       [43.        ],\n",
       "       [13.        ],\n",
       "       [17.        ],\n",
       "       [29.        ],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [25.        ],\n",
       "       [18.        ],\n",
       "       [ 8.        ],\n",
       "       [ 1.        ],\n",
       "       [46.        ],\n",
       "       [29.69911765],\n",
       "       [16.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [25.        ],\n",
       "       [39.        ],\n",
       "       [49.        ],\n",
       "       [31.        ],\n",
       "       [30.        ],\n",
       "       [30.        ],\n",
       "       [34.        ],\n",
       "       [31.        ],\n",
       "       [11.        ],\n",
       "       [ 0.42      ],\n",
       "       [27.        ],\n",
       "       [31.        ],\n",
       "       [39.        ],\n",
       "       [18.        ],\n",
       "       [39.        ],\n",
       "       [33.        ],\n",
       "       [26.        ],\n",
       "       [39.        ],\n",
       "       [35.        ],\n",
       "       [ 6.        ],\n",
       "       [30.5       ],\n",
       "       [29.69911765],\n",
       "       [23.        ],\n",
       "       [31.        ],\n",
       "       [43.        ],\n",
       "       [10.        ],\n",
       "       [52.        ],\n",
       "       [27.        ],\n",
       "       [38.        ],\n",
       "       [27.        ],\n",
       "       [ 2.        ],\n",
       "       [29.69911765],\n",
       "       [29.69911765],\n",
       "       [ 1.        ],\n",
       "       [29.69911765],\n",
       "       [62.        ],\n",
       "       [15.        ],\n",
       "       [ 0.83      ],\n",
       "       [29.69911765],\n",
       "       [23.        ],\n",
       "       [18.        ],\n",
       "       [39.        ],\n",
       "       [21.        ],\n",
       "       [29.69911765],\n",
       "       [32.        ],\n",
       "       [29.69911765],\n",
       "       [20.        ],\n",
       "       [16.        ],\n",
       "       [30.        ],\n",
       "       [34.5       ],\n",
       "       [17.        ],\n",
       "       [42.        ],\n",
       "       [29.69911765],\n",
       "       [35.        ],\n",
       "       [28.        ],\n",
       "       [29.69911765],\n",
       "       [ 4.        ],\n",
       "       [74.        ],\n",
       "       [ 9.        ],\n",
       "       [16.        ],\n",
       "       [44.        ],\n",
       "       [18.        ],\n",
       "       [45.        ],\n",
       "       [51.        ],\n",
       "       [24.        ],\n",
       "       [29.69911765],\n",
       "       [41.        ],\n",
       "       [21.        ],\n",
       "       [48.        ],\n",
       "       [29.69911765],\n",
       "       [24.        ],\n",
       "       [42.        ],\n",
       "       [27.        ],\n",
       "       [31.        ],\n",
       "       [29.69911765],\n",
       "       [ 4.        ],\n",
       "       [26.        ],\n",
       "       [47.        ],\n",
       "       [33.        ],\n",
       "       [47.        ],\n",
       "       [28.        ],\n",
       "       [15.        ],\n",
       "       [20.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [56.        ],\n",
       "       [25.        ],\n",
       "       [33.        ],\n",
       "       [22.        ],\n",
       "       [28.        ],\n",
       "       [25.        ],\n",
       "       [39.        ],\n",
       "       [27.        ],\n",
       "       [19.        ],\n",
       "       [29.69911765],\n",
       "       [26.        ],\n",
       "       [32.        ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.fit_transform(t[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked      2\n",
       "deck        688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[['embarked','deck']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a new object for str data\n",
    "si2 = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "      <th>deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked deck\n",
       "0        S  NaN\n",
       "1        C    C\n",
       "2        S  NaN"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[['embarked','deck']][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embarked</th>\n",
       "      <th>deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  embarked deck\n",
       "0        S    C"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[['embarked','deck']].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['S', 'C'],\n",
       "       ['C', 'C'],\n",
       "       ['S', 'C'],\n",
       "       ...,\n",
       "       ['S', 'C'],\n",
       "       ['C', 'C'],\n",
       "       ['Q', 'C']], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si2.fit_transform(t[['embarked','deck']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical data:\n",
    "\n",
    "- Categorical data is data which has some categories such as,  Country\n",
    "\n",
    "\n",
    "- Since machine learning model completely works on mathematics and numbers, but if our dataset would have a categorical variable, then it may create trouble while building the model. So it is necessary to encode these categorical variables into numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[0].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Categorical data is of 2 types:\n",
    "    -Nominal data (where sequence order doesnt matter)\n",
    "     Ex. Male/Female, CountryNames, ColorNames, VehicleName , ObjectNames\n",
    "        \n",
    "    - Ordinal data (where sequence order matters)\n",
    "    Ex. Result, Rank, EducationLevel,Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using replace--> Assignment\n",
    "df[0].replace({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "#lets supply country data present at 0 index\n",
    "lb.fit_transform(df[0])\n",
    "#in above case labelencoder converted India as 2, France as 0 and germany as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.classes_\n",
    "#LabelEncoder follows Alphabatic order a-z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = pd.DataFrame({'gender':['male','female','female','male','male','female'],\n",
    "             'cat':['A','A','A','B','C','C']})\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb2 = LabelEncoder()\n",
    "#labelEncode accepts only 1D data\n",
    "lb2.fit(g['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb2.transform(g.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will labelEncoder work on 2 columns\n",
    "lb2.fit_transform(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will use titanic dataset\n",
    "# in which we have sex column will convert Male and Female in 1 and 0\n",
    "import seaborn as sns\n",
    "t = sns.load_dataset('titanic')\n",
    "t['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use lb2 to convert above series into 0 &1\n",
    "lb2.fit_transform(t['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= [1,1,1,1,1,0,0,0,0,0,1,0,1,1,1,0,0,1,1,0,1]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert above 0 & 1 into Category male and female\n",
    "lb2.inverse_transform(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interview question:\n",
    "# What are different ways to deal with Categorical data?\n",
    "# How to convert categorical data using pandas\n",
    "# how to convert categorical data using sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variables:\n",
    "\n",
    "- Dummy variables are those variables which have values 0 or 1. \n",
    "\n",
    "\n",
    "- The 1 value gives the presence of that variable in a particular column, and rest variables become 0. \n",
    "\n",
    "\n",
    "- With dummy encoding, we will have a number of columns equal to the number of categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place = pd.DataFrame({'data':['Katraj','Camp','Hadapsar','Katraj','Katraj','Hadapsar','Camp','Camp','Hadapsar']})\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place.data.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wherever we have categorical data ina column, there u have to apply OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding for dummy variables using OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ob = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = ob.fit_transform(place)\n",
    "convert\n",
    "#return sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final = convert.toarray()\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the sequence of conversion\n",
    "ob.categories_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#once we get converted category into columns\n",
    "#then next step is to add thse conversions in original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "place[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert final into dataFrame\n",
    "fin = pd.DataFrame(final,dtype=int)\n",
    "d1 = pd.concat([place,fin],axis=1)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.drop(columns='data',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "d1.columns= ob.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas: get_dummies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### alternative option and simple option to OneHot is get_dummies() of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to deal with categorical data\n",
    "# WHat are different encoding techniques?\n",
    "# difference btween onehot and get_dummies\n",
    "# what is dummy variable trap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "- Feature scaling is the final step of data preprocessing in machine learning. \n",
    "\n",
    "\n",
    "- It is a technique to standardize the independent variables of the dataset in a specific range. \n",
    "\n",
    "\n",
    "- In feature scaling, we put our variables in the same range and in the same scale so that no any variable dominate the other variable. \n",
    "\n",
    "#age = 30,40,50\n",
    "#salary = 65000,56000,150000,240000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 2 types:\n",
    "    - Standardization x-M(mue/meanofX)/sigma (std deviation)\n",
    "    - Normalization x- min(x)/(max(x)-min(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler   # x -mean(total_x)/std(total_x) -3 0 +3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load boston_housing dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('boston.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load StandardScalar\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = sc.fit_transform(df)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lets convert  new to df\n",
    "ndf = pd.DataFrame(new)\n",
    "ndf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndf.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now lets check hist plot of both\n",
    "#df\n",
    "df.CRIM.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndf[0].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ndf[0].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CRIM'].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler  # x- min()/(max()-min())\n",
    "#range of minMax scalar is 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx = MinMaxScaler()\n",
    "norm = mx.fit_transform(df)\n",
    "normdf = pd.DataFrame(norm)\n",
    "normdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normdf[0].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normdf.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizer is threshold based\n",
    "# threshold is depends on condition\n",
    "# if condition is True then convert samples to 1\n",
    "# else 0\n",
    "\"\"\"\n",
    "Values greater than the threshold map to 1, while values less than\n",
    "or equal to the threshold map to 0. With the default threshold of 0,\n",
    "only positive values map to 1.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select target column from df\n",
    "#which contains prices\n",
    "out = df[['target']]\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Binarizer(threshold=28)\n",
    "# values >28 ==>1\n",
    "#values <=28 ==> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi.fit_transform(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
